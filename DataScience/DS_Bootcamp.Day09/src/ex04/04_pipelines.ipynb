{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 04\n",
    "# Pipelines and OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three custom transformers, the first two out of which will be used within a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "1. `FeatureExtractor()` class:\n",
    " - Takes a dataframe with `uid`, `labname`, `numTrials`, `timestamp` from the file [`checker_submits.csv`](https://drive.google.com/file/d/14voc4fNJZiLEFaZyd8nEG-lQt5JjatYw/view?usp=sharing).\n",
    " - Extracts `hour` from `timestamp`.\n",
    " - Extracts `weekday` from `timestamp` (numbers).\n",
    " - Drops the `timestamp` column.\n",
    " - Returns the new dataframe.\n",
    "\n",
    "\n",
    "2. `MyOneHotEncoder()` class:\n",
    " - Takes the dataframe from the result of the previous transformation and the name of the target column.\n",
    " - Identifies all the categorical features and transforms them with `OneHotEncoder()`. If the target column is categorical too, then the transformation should not apply to it.\n",
    " - Drops the initial categorical features.\n",
    " - Returns the dataframe with the features and the series with the target column.\n",
    "\n",
    "\n",
    "3. `TrainValidationTest()` class:\n",
    " - Takes `X` and `y`.\n",
    " - Returns `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` (`test_size=0.2`, `random_state=21`, `stratified`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extracts 'hour' and 'weekday' from the 'timestamp' column and drops the original 'timestamp'.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['timestamp'] = pd.to_datetime(X_copy['timestamp'])\n",
    "        X_copy['hour'] = X_copy['timestamp'].dt.hour\n",
    "        X_copy['weekday'] = X_copy['timestamp'].dt.weekday\n",
    "        X_copy = X_copy.drop('timestamp', axis=1)\n",
    "        return X_copy\n",
    "\n",
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Performs One-Hot Encoding on categorical features.\n",
    "    Excludes the specified target column from encoding if it's also categorical.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_column=None):\n",
    "        self.target_column = target_column\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        self.categorical_features = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if self.target_column and self.target_column in self.categorical_features:\n",
    "            self.categorical_features.remove(self.target_column)\n",
    "\n",
    "        if self.categorical_features:\n",
    "            self.encoder.fit(X[self.categorical_features])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        y = None\n",
    "        if self.target_column:\n",
    "            y = X_copy[self.target_column]\n",
    "            X_copy = X_copy.drop(columns=[self.target_column])\n",
    "\n",
    "        if not self.categorical_features:\n",
    "            return X_copy, y\n",
    "\n",
    "        encoded_features = self.encoder.transform(X_copy[self.categorical_features])\n",
    "        encoded_df = pd.DataFrame(encoded_features, columns=self.encoder.get_feature_names(self.categorical_features), index=X_copy.index)\n",
    "\n",
    "        X_copy = X_copy.drop(columns=self.categorical_features)\n",
    "\n",
    "        X_processed = pd.concat([X_copy, encoded_df], axis=1)\n",
    "\n",
    "        return X_processed, y\n",
    "\n",
    "class TrainValidationTest:\n",
    "    \"\"\"\n",
    "    Splits data into training, validation, and test sets.\n",
    "    Handles stratification dynamically for each split to avoid ValueError.\n",
    "    \"\"\"\n",
    "    def __init__(self, test_size=0.2, random_state=21):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _get_stratify_param(self, y_data, split_name=\"\"):\n",
    "        \"\"\"Checks the least populated class in y and returns the stratify parameter.\"\"\"\n",
    "        class_counts = y_data.value_counts()\n",
    "        min_class_count = class_counts.min()\n",
    "        if min_class_count < 2:\n",
    "            print(f\"Warning ({split_name} split): Least populated class has {min_class_count} member(s). Stratification set to FALSE.\")\n",
    "            return None\n",
    "        else:\n",
    "            return y_data\n",
    "\n",
    "    def split(self, X, y):\n",
    "        stratify_y_1 = self._get_stratify_param(y, \"Initial\")\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state, stratify=stratify_y_1\n",
    "        )\n",
    "\n",
    "        test_valid_ratio = 0.2\n",
    "        stratify_y_2 = self._get_stratify_param(y_temp, \"Valid/Test\")\n",
    "        X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=test_valid_ratio, random_state=self.random_state, stratify=stratify_y_2\n",
    "        )\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelSelection()` class\n",
    "\n",
    " - Takes a list of `GridSearchCV` instances and a dict where the keys are the indexes from that list and the values are the names of the models, the example is below in the reverse order (from high-level to low-level perspective):\n",
    "\n",
    "```\n",
    "ModelSelection(grids, grid_dict)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs), where jobs you can specify by yourself\n",
    "\n",
    "svm_params = [{'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 1.5, 5, 10], 'gamma': ['scale', 'auto'], 'class_weight':('balanced', None), 'random_state':[21], 'probability':[True]}]\n",
    "```\n",
    "\n",
    " - Method `choose()` takes `X_train`, `y_train`, `X_valid`, `y_valid` and returns the name of the best classifier among all the models on the validation set\n",
    " - Method `best_results()` returns a dataframe with the columns `model`, `params`, `valid_score` where the rows are the best models within each class of models.\n",
    "\n",
    "```\n",
    "model\tparams\tvalid_score\n",
    "0\tSVM\t{'C': 10, 'class_weight': None, 'gamma': 'auto...\t0.772727\n",
    "1\tDecision Tree\t{'class_weight': 'balanced', 'criterion': 'gin...\t0.801484\n",
    "2\tRandom Forest\t{'class_weight': None, 'criterion': 'entropy',...\t0.855288\n",
    "```\n",
    "\n",
    " - When you iterate through the parameters of a model class, print the name of that class and show the progress using `tqdm.notebook`, in the end of the cycle print the best model of that class.\n",
    "\n",
    "```\n",
    "Estimator: SVM\n",
    "100%\n",
    "125/125 [01:32<00:00, 1.36it/s]\n",
    "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
    "Best training accuracy: 0.773\n",
    "Validation set accuracy score for best params: 0.878 \n",
    "\n",
    "Estimator: Decision Tree\n",
    "100%\n",
    "57/57 [01:07<00:00, 1.22it/s]\n",
    "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21, 'random_state': 21}\n",
    "Best training accuracy: 0.801\n",
    "Validation set accuracy score for best params: 0.867 \n",
    "\n",
    "Estimator: Random Forest\n",
    "100%\n",
    "284/284 [06:47<00:00, 1.13s/it]\n",
    "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 50, 'random_state': 21}\n",
    "Best training accuracy: 0.855\n",
    "Validation set accuracy score for best params: 0.907 \n",
    "\n",
    "Classifier with best validation set accuracy: Random Forest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class for selecting the best model from given GridSearchCV instances and\n",
    "    returning the best results for each model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, grids: list, grid_dict: dict):\n",
    "        if not isinstance(grids, list) or not all(isinstance(g, GridSearchCV) for g in grids):\n",
    "            raise TypeError(\"`grids` must be a list containing only GridSearchCV instances.\")\n",
    "        if not isinstance(grid_dict, dict) or not all(isinstance(k, int) and isinstance(v, str) for k, v in grid_dict.items()):\n",
    "            raise TypeError(\"`grid_dict` must be a dictionary with integer keys and string values.\")\n",
    "        if not all(i < len(grids) for i in grid_dict.keys()):\n",
    "            raise ValueError(\"Indices in `grid_dict` must not exceed the length of the `grids` list.\")\n",
    "\n",
    "        self.grids = grids\n",
    "        self.grid_dict = grid_dict\n",
    "        self.best_classifiers = []\n",
    "        self.best_overall_classifier_name = None\n",
    "        self.best_overall_validation_score = -1.0\n",
    "        self.best_overall_estimator = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def choose(self, X_train, y_train, X_valid, y_valid):\n",
    "        self.best_classifiers = []\n",
    "        self.best_overall_validation_score = -1.0\n",
    "        self.best_overall_classifier_name = None\n",
    "        self.best_overall_estimator = None\n",
    "\n",
    "        sorted_keys = sorted(self.grid_dict.keys())\n",
    "\n",
    "        for idx in tqdm(sorted_keys, desc=\"Training and evaluating models\"):\n",
    "            model_name = self.grid_dict[idx]\n",
    "            gs_estimator = self.grids[idx]\n",
    "\n",
    "            print(f\"\\nEstimator: {model_name}\")\n",
    "\n",
    "            gs_estimator.fit(X_train, y_train)\n",
    "\n",
    "            best_estimator = gs_estimator.best_estimator_\n",
    "            best_params = gs_estimator.best_params_\n",
    "            best_train_score = gs_estimator.best_score_\n",
    "\n",
    "            y_valid_pred = best_estimator.predict(X_valid)\n",
    "            valid_score = accuracy_score(y_valid, y_valid_pred)\n",
    "\n",
    "            print(f\"Best params: {best_params}\")\n",
    "            print(f\"Best training accuracy: {best_train_score:.3f}\")\n",
    "            print(f\"Validation set accuracy score for best params: {valid_score:.3f}\")\n",
    "\n",
    "            self.best_classifiers.append({\n",
    "                'model': model_name,\n",
    "                'params': best_params,\n",
    "                'valid_score': valid_score,\n",
    "                'train_score': best_train_score\n",
    "            })\n",
    "\n",
    "            if valid_score > self.best_overall_validation_score:\n",
    "                self.best_overall_validation_score = valid_score\n",
    "                self.best_overall_classifier_name = model_name\n",
    "                self.best_overall_estimator = best_estimator\n",
    "\n",
    "        print(f\"\\nClassifier with best validation set accuracy: {self.best_overall_classifier_name}\")\n",
    "        return self.best_overall_classifier_name\n",
    "\n",
    "    def best_results(self):\n",
    "        if not self.best_classifiers:\n",
    "            print(\"Please call `choose()` method first.\")\n",
    "            return pd.DataFrame(columns=['model', 'params', 'valid_score'])\n",
    "\n",
    "        results_df = pd.DataFrame(self.best_classifiers)\n",
    "        return results_df[['model', 'params', 'valid_score']]\n",
    "\n",
    "    def get_best_estimator(self):\n",
    "        return self.best_overall_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Finalize()` class\n",
    " - Takes an estimator.\n",
    " - Method `final_score()` takes `X_train`, `y_train`, `X_test`, `y_test` and returns the accuracy of the model as in the example below:\n",
    "```\n",
    "final.final_score(X_train, y_train, X_test, y_test)\n",
    "Accuracy of the final model is 0.908284023668639\n",
    "```\n",
    " - Method `save_model()` takes a path, saves the model to this path and prints that the model was successfully saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finalize(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class for final training, evaluation, and saving of the selected estimator.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator):\n",
    "        if not hasattr(estimator, 'fit') or not hasattr(estimator, 'predict'):\n",
    "            raise ValueError(\"The provided estimator must have 'fit' and 'predict' methods.\")\n",
    "        self.estimator = estimator\n",
    "        self.final_model_accuracy = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def final_score(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the model on X_train, y_train and evaluates it on X_test, y_test.\n",
    "        Returns the accuracy on the test dataset.\n",
    "        \"\"\"\n",
    "        print(f\"Final model ({type(self.estimator).__name__}) is being trained...\")\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Model is being evaluated on the test set...\")\n",
    "        y_pred = self.estimator.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        self.final_model_accuracy = accuracy\n",
    "        print(f\"Accuracy of the final model is {accuracy:.15f}\")\n",
    "        return accuracy\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"\n",
    "        Saves the trained model to the specified path.\n",
    "        path: File path where the model will be saved (e.g., 'models/final_model.joblib').\n",
    "        \"\"\"\n",
    "        try:\n",
    "            joblib.dump(self.estimator, path)\n",
    "            print(f\"Model successfully saved to {path}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving the model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data from the file (****name of file****).\n",
    "2. Create the preprocessing pipeline that consists of two custom transformers: `FeatureExtractor()` and `MyOneHotEncoder()`:\n",
    "```\n",
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])\n",
    "```\n",
    "3. Use that pipeline and its method `fit_transform()` on the initial dataset.\n",
    "```\n",
    "data = preprocessing.fit_transform(df)\n",
    "```\n",
    "4. Get `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` using `TrainValidationTest()` and the result of the pipeline.\n",
    "5. Create an instance of `ModelSelection()`, use the method `choose()` applying it to the models that you want and parameters that you want, get the dataframe of the best results.\n",
    "6. create an instance of `Finalize()` with your best model, use method `final_score()` and save the model in the format: `name_of_the_model_{accuracy on test dataset}.sav`.\n",
    "\n",
    "That is it, congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for 'labname' column (original):\n",
      "labname\n",
      "project1    951\n",
      "laba05      222\n",
      "laba04      178\n",
      "laba04s     104\n",
      "code_rvw     82\n",
      "laba06s      61\n",
      "laba06       48\n",
      "lab05s       36\n",
      "lab02         2\n",
      "lab03         1\n",
      "lab03s        1\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "Merging the following rare classes in 'labname' into 'Other_Labs': ['lab03', 'lab03s']\n",
      "Class distribution for 'labname' column (updated):\n",
      "labname\n",
      "project1      951\n",
      "laba05        222\n",
      "laba04        178\n",
      "laba04s       104\n",
      "code_rvw       82\n",
      "laba06s        61\n",
      "laba06         48\n",
      "lab05s         36\n",
      "Other_Labs      2\n",
      "lab02           2\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "Preprocessing pipeline is being applied...\n",
      "\n",
      "Least populated class in 'labname' after merging: 2. Splitter will enable stratification.\n",
      "\n",
      "Splitting data into training, validation, and test sets...\n",
      "X_train shape: (1348, 33), y_train shape: (1348,)\n",
      "X_valid shape: (270, 33), y_valid shape: (270,)\n",
      "X_test shape: (68, 33), y_test shape: (68,)\n",
      "------------------------------\n",
      "Number of CPU cores to use (n_jobs): 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9f18acdb7b4e1b9aeca914fa79c611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training and evaluating models', max=3.0, style=ProgressSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimator: SVM\n",
      "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best training accuracy: 0.777\n",
      "Validation set accuracy score for best params: 0.837\n",
      "\n",
      "Estimator: Decision Tree\n",
      "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21}\n",
      "Best training accuracy: 0.800\n",
      "Validation set accuracy score for best params: 0.822\n",
      "\n",
      "Estimator: Random Forest\n",
      "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 50}\n",
      "Best training accuracy: 0.843\n",
      "Validation set accuracy score for best params: 0.878\n",
      "\n",
      "\n",
      "Classifier with best validation set accuracy: Random Forest\n",
      "\n",
      "Best classifier chosen: Random Forest\n",
      "\n",
      "Best results for each model class:\n",
      "           model                                             params  \\\n",
      "0            SVM  {'C': 10, 'class_weight': None, 'gamma': 'auto...   \n",
      "1  Decision Tree  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
      "2  Random Forest  {'class_weight': None, 'criterion': 'entropy',...   \n",
      "\n",
      "   valid_score  \n",
      "0     0.837037  \n",
      "1     0.822222  \n",
      "2     0.877778  \n",
      "------------------------------\n",
      "Final model (RandomForestClassifier) is being trained...\n",
      "Model is being evaluated on the test set...\n",
      "Accuracy of the final model is 0.867647058823529\n",
      "Model successfully saved to models\\randomforestclassifier_0.867647058823529.sav.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"data/checker_submits.csv\")\n",
    "    target_col = 'labname'\n",
    "\n",
    "    print(f\"Class distribution for '{target_col}' column (original):\")\n",
    "    print(df[target_col].value_counts())\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    threshold_count_for_merge = 2\n",
    "    value_counts = df[target_col].value_counts()\n",
    "    rare_classes = value_counts[value_counts < threshold_count_for_merge].index.tolist()\n",
    "\n",
    "    if rare_classes:\n",
    "        print(f\"Merging the following rare classes in '{target_col}' into 'Other_Labs': {rare_classes}\")\n",
    "        df[target_col] = df[target_col].replace(rare_classes, 'Other_Labs')\n",
    "        print(f\"Class distribution for '{target_col}' column (updated):\")\n",
    "        print(df[target_col].value_counts())\n",
    "    else:\n",
    "        print(f\"No classes with less than {threshold_count_for_merge} members found in '{target_col}'. No merging performed.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    preprocessing = Pipeline([\n",
    "        ('feature_extractor', FeatureExtractor()),\n",
    "        ('onehot_encoder', MyOneHotEncoder(target_column=target_col))\n",
    "    ])\n",
    "\n",
    "    print(\"Preprocessing pipeline is being applied...\")\n",
    "    X_processed, y_target = preprocessing.fit_transform(df)\n",
    "\n",
    "    min_class_count_after_merge = y_target.value_counts().min()\n",
    "    if min_class_count_after_merge < 2:\n",
    "        print(f\"\\nWarning: Even after merging, '{target_col}' has classes with {min_class_count_after_merge} member(s). Splitter will handle stratification.\")\n",
    "    else:\n",
    "        print(f\"\\nLeast populated class in '{target_col}' after merging: {min_class_count_after_merge}. Splitter will enable stratification.\")\n",
    "\n",
    "\n",
    "    print(\"\\nSplitting data into training, validation, and test sets...\")\n",
    "    splitter = TrainValidationTest(test_size=0.2, random_state=21)\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = splitter.split(X_processed, y_target)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_valid shape: {X_valid.shape}, y_valid shape: {y_valid.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    jobs = multiprocessing.cpu_count() - 1\n",
    "    if jobs == 0: jobs = 1\n",
    "    print(f\"Number of CPU cores to use (n_jobs): {jobs}\")\n",
    "\n",
    "    svm = SVC(random_state=21, probability=True)\n",
    "    svm_params = [{'kernel':('linear', 'rbf', 'sigmoid'),\n",
    "                   'C':[0.01, 0.1, 1, 1.5, 5, 10],\n",
    "                   'gamma': ['scale', 'auto'],\n",
    "                   'class_weight':('balanced', None)}]\n",
    "    gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs, verbose=0)\n",
    "\n",
    "    tree = DecisionTreeClassifier(random_state=21)\n",
    "    tree_params = [{'criterion':('gini', 'entropy'),\n",
    "                    'max_depth': list(range(5, 23, 2)),\n",
    "                    'class_weight':('balanced', None)}]\n",
    "    gs_tree = GridSearchCV(estimator=tree, param_grid=tree_params, scoring='accuracy', cv=2, n_jobs=jobs, verbose=0)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=21)\n",
    "    rf_params = [{'n_estimators':[10, 25, 50],\n",
    "                  'criterion':('gini', 'entropy'),\n",
    "                  'max_depth': list(range(10, 24, 2)),\n",
    "                  'class_weight':('balanced', None)}]\n",
    "    gs_rf = GridSearchCV(estimator=rf, param_grid=rf_params, scoring='accuracy', cv=2, n_jobs=jobs, verbose=0)\n",
    "\n",
    "    grids = [gs_svm, gs_tree, gs_rf]\n",
    "    grid_dict = {0: 'SVM', 1: 'Decision Tree', 2: 'Random Forest'}\n",
    "\n",
    "    model_selector = ModelSelection(grids=grids, grid_dict=grid_dict)\n",
    "    best_classifier_name = model_selector.choose(X_train, y_train, X_valid, y_valid)\n",
    "    print(f\"\\nBest classifier chosen: {best_classifier_name}\")\n",
    "\n",
    "    results_df = model_selector.best_results()\n",
    "    print(\"\\nBest results for each model class:\")\n",
    "    print(results_df)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    final_estimator = model_selector.get_best_estimator()\n",
    "\n",
    "    finalizer = Finalize(estimator=final_estimator)\n",
    "\n",
    "    final_accuracy = finalizer.final_score(X_train, y_train, X_test, y_test)\n",
    "    model_name_for_save = type(final_estimator).__name__.lower()\n",
    "    save_directory = 'models'\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    save_file_name = f\"{model_name_for_save}_{final_accuracy:.15f}.sav\"\n",
    "    model_save_path = os.path.join(save_directory, save_file_name)\n",
    "    finalizer.save_model(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
